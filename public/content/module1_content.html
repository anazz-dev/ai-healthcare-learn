<h2>Slide 1 – Why This Course Exists</h2>
<p>AI in healthcare is no longer future talk.<br/>It’s showing up in radiology suites, outpatient clinics, and EHRs.</p>
<p>But it’s also showing up in marketing pitches, buzzwords, and black-box tools that clinicians are asked to trust.<br/>This course gives you the tools to question, understand, and safely work with AI—no coding needed.</p>

<h2>Slide 2 – AI Isn’t Magic. It’s Pattern Recognition.</h2>
<p>AI doesn’t “understand” disease.<br/>It finds patterns in massive amounts of labelled data.</p>
<p>For example:<br/>You show an AI 100,000 chest X-rays with diagnoses. It learns that certain shapes and textures often mean “pneumonia.”</p>
<p>But unlike a clinician, it has no anatomy training, no context, no reasoning.</p>
<p>✅ AI = powerful pattern detector<br/>❌ AI ≠ medical thinker</p>

<h2>Slide 3 – AI Learns from Examples, Not Rules</h2>
<p>Traditional software uses if–then rules:<br/>“If blood glucose > 11 mmol/L, then flag as hyperglycaemia.”</p>
<p>AI doesn’t follow rules. It learns from examples:</p>
<ul>
    <li>Thousands of CT scans labeled “stroke” or “normal”</li>
    <li>Tens of thousands of ECGs labeled by cardiologists</li>
</ul>
<p>It then builds its own internal shortcuts.</p>
<p>But these shortcuts are hidden and not always reliable.</p>

<h2>Slide 4 – Clinical Analogy: Teaching a Junior Doctor</h2>
<p>Think of AI like a very fast junior doctor with a photographic memory but no common sense.<br/>You show it 10,000 melanoma cases.<br/>It sees that “dark, asymmetric, irregular” equals “melanoma.”</p>
<p>But what if all the melanoma images came from one hospital with a specific lighting setup?</p>
<p>Then the AI might learn:<br/>“Dim lighting = melanoma.” Not what we want.</p>

<h2>Slide 5 – Bullet Recap: What AI Is (and Isn’t)</h2>
<p><strong>AI IS:</strong></p>
<ul>
    <li>A system that learns patterns from data</li>
    <li>Often faster and more consistent than humans</li>
    <li>Able to improve with more data</li>
</ul>
<p><strong>AI ISN’T:</strong></p>
<ul>
    <li>Capable of understanding causality or meaning</li>
    <li>Immune to mistakes</li>
    <li>A substitute for clinical judgment</li>
</ul>

<h2>Slide 6 – AI Can Fail in Surprising Ways</h2>
<p>🧪 A pneumonia-detection AI worked in one hospital but failed in another. Why?<br/>It had learned to associate metal markers used in certain images with “pneumonia.”</p>
<p>🧪 A skin cancer model underperformed on dark skin tones. Why?<br/>The model was mostly trained on light-skinned patients.</p>
<p>AI will learn whatever it’s given—even if the pattern is irrelevant or unfair.</p>

<h2>Slide 7 – The “Garbage In, Garbage Out” Principle</h2>
<p>If your training data is:</p>
<ul>
    <li>Biased (e.g., missing certain ethnic groups)</li>
    <li>Incomplete (e.g., poor-quality labels)</li>
    <li>Inconsistent (e.g., mixed annotation standards)</li>
</ul>
<p>Then your model will be too.</p>
<p>Better training = safer tools.<br/>That’s why clinicians need to ask about data quality, not just accuracy.</p>

<h2>Slide 8 – Your Role as a Clinician</h2>
<p>You don’t need to build AI.<br/>But you must understand:</p>
<ul>
    <li>What data it was trained on</li>
    <li>Whether it was validated on real-world patients</li>
    <li>Whether its predictions make clinical sense</li>
</ul>
<p>AI needs clinical oversight—yours.</p>

<h2>Slide 9 – Summary (Key Messages)</h2>
<ul>
    <li>AI = pattern learning from examples, not rules or logic</li>
    <li>It’s powerful, but blindly statistical</li>
    <li>It can make mistakes if trained on biased or poor data</li>
    <li>You can’t trust it blindly—interrogate it like any other clinical tool</li>
</ul>

<!-- Quiz Placeholder -->
<div id="quiz-placeholder"></div>

